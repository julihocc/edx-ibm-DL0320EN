{"cells":[{"cell_type":"markdown","metadata":{},"source":["<a href=\"https://cocl.us/DL0320EN_TOP_IMAGE\">\n","    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0320EN/Assets/Images/Top.png\" width=\"750\" alt=\"IBM 10TB Storage\">\n","</a>\n"]},{"cell_type":"markdown","metadata":{},"source":["<h1>Classifying European Money Denominations</h1>\n"]},{"cell_type":"markdown","metadata":{},"source":["<h2>Table of Contents</h2>\n"]},{"cell_type":"markdown","metadata":{},"source":["<p>In this lab, you will learn how to load image folder in Keras. Test the images by the libraries in the matplotlib.</p>\n","<ul>\n","    <li><a href=\"#load_image\">Load Image</a></li>\n","    <li><a href=\"#ques\">Questions</a>\n","        <ol>\n","            <li><a href=\"#q21\">Question 2.1</a></li>\n","            <li><a href=\"#q22\">Question 2.2</a></li>\n","        </ol>\n","    </li>\n","\n","</ul>\n","\n","<p>Estimated Time Needed: <b>30 min</b></p>\n","<hr>\n"]},{"cell_type":"markdown","metadata":{},"source":["<h2>Preparation</h2>\n"]},{"cell_type":"markdown","metadata":{},"source":["<a href=\"https://cocl.us/DL0320EN_storage\">\n","    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0320EN/Assets/Images/ObjectStorage.png\" width=\"750\" alt=\"cognitive class\">\n","</a>\n"]},{"cell_type":"markdown","metadata":{},"source":["Download the datasets you needed for this lab.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# You can comment the code in this box out if you already have the dataset.\n","# Step 1: Ctrl + A : Select all\n","# Step 2: Ctrl + / : Comment out all; if everything selected has been comment out alreaday, then uncomment all\n","\n","# Download Training Dataset\n","!wget --quiet -O /resources/data/train_data_keras.tar.gz https://cocl.us/DL0320EN_TRAIN_TAR_KERAS\n","!tar -xzf /resources/data/train_data_keras.tar.gz -C /resources/data --exclude '.*'\n","\n","# Download Validation Dataset\n","!wget --quiet -O /resources/data/validation_data_keras.tar.gz https://cocl.us/DL0320EN_VALID_TAR_KERAS\n","!tar -xzf /resources/data/validation_data_keras.tar.gz -C /resources/data --exclude '.*'"]},{"cell_type":"markdown","metadata":{},"source":["The following are the Keras modules you are going to need\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Import Keras Modules\n","\n","import keras\n","from keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"markdown","metadata":{},"source":["Import Non-Keras Modules \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Import Non-Keras Modules\n","\n","import os\n","from matplotlib.pyplot import imshow\n","import matplotlib.pylab as plt\n","import pandas as pd\n","from PIL import Image\n","import numpy as np "]},{"cell_type":"markdown","metadata":{},"source":["Set the parameters\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Parameters for the image dataset generators\n","\n","TARGET_SIZE = (224, 224)\n","BATCH_SIZE = 5\n","CLASSES = ['5', '10', '20', '50', '100', '200', '500']\n","RANDOM_SEED = 0"]},{"cell_type":"markdown","metadata":{},"source":["<hr>\n"]},{"cell_type":"markdown","metadata":{},"source":["<h2 id=\"load_image\">Load Image</h2>\n"]},{"cell_type":"markdown","metadata":{},"source":["<h3>Training Images</h3>\n"]},{"cell_type":"markdown","metadata":{},"source":["The train images are stored in the following directory \n","<code>/resources/data/train_data_keras/</code>. We can save it in the variable <code>train_data_dir</code>.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get the train dataset folder and store it in train_data_dir\n","\n","train_data_dir = '/resources/data/train_data_keras'"]},{"cell_type":"markdown","metadata":{},"source":["To load the image, you need the directory that contains the entire dataset. Then you can use the <code>ImageDataGenerator()</code> with <code>flow_from_directory()</code> to get the images from folder and load them into a data object.<br>\n","In function <code>flow_from_directory()</code>, you can set the directory path that contains the entire dataset.<br>\n","You can set the target size of images, set the batch size, set the classes which are the labels in the dataset and the random seed.<br>\n","The labels are the sub-folder names like <i>5</i>, <i>10</i>, <i>20</i> ... In our dataset, there are 7 different labels. (5, 10, 20, 50, 100, 200, 500)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Generate training image dataset\n","\n","train_generator = ImageDataGenerator().flow_from_directory(train_data_dir\n","                                                           , target_size=TARGET_SIZE\n","                                                           , batch_size=BATCH_SIZE\n","                                                           , classes=CLASSES\n","                                                           , seed=RANDOM_SEED)"]},{"cell_type":"markdown","metadata":{},"source":["<h3>Validation Images</h3>\n"]},{"cell_type":"markdown","metadata":{},"source":["The validation data is stored in the following directory <code>/resources/data/validation_data_keras</code>. We can assign it to the variable   <code>validation_data_dir</code>.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get the validation dataset folder and store it in validation_data_dir\n","\n","validation_data_dir = '/resources/data/validation_data_keras'"]},{"cell_type":"markdown","metadata":{},"source":["<h3>Try</h3>\n"]},{"cell_type":"markdown","metadata":{},"source":["Use the same procedure as above to load and plot the first validation image in the validation set <b>(Please use the parameter defined in preparation section when you are trying to get the answer for the questions in the next section)</b>:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# A practice that won't be graded, but you need it to complete the following questions\n","\n","# Type your code here"]},{"cell_type":"markdown","metadata":{},"source":["Double-click <b>here</b> for the solution.\n","<!--\n","valid_generator = ImageDataGenerator().flow_from_directory(validation_data_dir\n","                                                           , target_size=TARGET_SIZE\n","                                                           , batch_size=BATCH_SIZE\n","                                                           , classes=CLASSES\n","                                                           , seed=RANDOM_SEED)\n","-->\n"]},{"cell_type":"markdown","metadata":{},"source":["<hr>\n"]},{"cell_type":"markdown","metadata":{},"source":["<h2 id=\"ques\">Questions</h2>\n"]},{"cell_type":"markdown","metadata":{},"source":["In this section, you will test your dataset object. Please plot out the images in the first batch.\n"]},{"cell_type":"markdown","metadata":{},"source":["If you generate the dataset correctly, there are 5 European Bills are going to be plot out.\n"]},{"cell_type":"markdown","metadata":{},"source":["<i>Hint: <br>\n","<ol>\n","    <li>Use <code>image_generator.batch_size</code> to get the batch size.</li>\n","    <li>Create a loop to get each image</li>\n","    <li>Use <code>image_generator.next()[0]</code> to get the first batch</li>\n","    <li>Convert the image array to <code>np.uint8</code> by <code>obj.astype(np.uint8)</code> before you plot them</li>\n","    <li>Use the <code>plt.imshow(image)</code> and <code>plt.show()</code> to plot the image</li>\n","</ol>\n","</i>\n"]},{"cell_type":"markdown","metadata":{},"source":["<h3 id=\"q21\">Question 2.1</h3>\n"]},{"cell_type":"markdown","metadata":{},"source":["Test the training dataset.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Question 2.1\n","\n","# Type your code here"]},{"cell_type":"markdown","metadata":{},"source":["<h3 id=\"q22\">Question 2.2</h3>\n"]},{"cell_type":"markdown","metadata":{},"source":["Test the validation dataset.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Question 2.2\n","\n","# Type your code here"]},{"cell_type":"markdown","metadata":{},"source":["<a href=\"https://cocl.us/DLO0320EN_notebook_bott\">\n","    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0320EN/Assets/Images/Bottom.png\" width=\"750\" alt=\"cognitive class\">\n","</a>\n"]},{"cell_type":"markdown","metadata":{},"source":["<h2>About the Authors:</h2> \n","\n","<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0320ENSkillsNetwork929-2023-01-01\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n"]},{"cell_type":"markdown","metadata":{},"source":["Other contributors: <a href=\"https://www.linkedin.com/in/michelleccarey/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0320ENSkillsNetwork929-2023-01-01\">Michelle Carey</a>, <a href=\"www.linkedin.com/in/jiahui-mavis-zhou-a4537814a\">Mavis Zhou</a>, <a href=\"https://www.linkedin.com/in/yi-leng-yao-84451275/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0320ENSkillsNetwork929-2023-01-01\">Yi Leng Yao</a>\n"]},{"cell_type":"markdown","metadata":{},"source":["<hr>\n"]},{"cell_type":"markdown","metadata":{},"source":["Copyright &copy; 2018 <a href=\"cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0320ENSkillsNetwork929-2023-01-01\">MIT License</a>.\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""}},"nbformat":4,"nbformat_minor":2}